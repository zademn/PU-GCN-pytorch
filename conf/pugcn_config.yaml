#Configuration for creating the model. These will be passed as arguments to PUGCN
name: pugcn-baseline
model_config:
    r: 4 # upsampling ratio
    k: 20 # num neighbours in DenseGCN
    dilations: [1, 2] # dilation in DenseGCN
    n_idgcn_blocks: 1 # number of inception dense blocks
    channels: 24 # number of channels for gcn
    n_dgcn_blocks: 2 # number of DenseGCNBlocks in the DenseGCN
    use_bottleneck: True # True - Applies a bottleneck 1 layer MLP with dimensions [in_channels, growth_rate / n_dgcn_blocks] in InceptionDenseGCN.
    use_pooling: True # True - applies a `global_max_pool` and in parallel to the DenseGCN
    use_residual: True # True - adds the inputs to the result in InceptionDenseGCN
    conv: "edge" # Convoltuion type in DenseGraphBlock One of ["edge", "mr", "gat", "gcn", "gin", "sage", "rsage"]
    pool_type: "mean" #  global pooling type if `use_pooling == True`. One of ["max", "mean", "add"]
    dynamic: False # if the graph should be compute at the start of every InceptionDenseGCN block.
    use_refiner: True # If to use a RefinerTransformer
    upsampler: "nodeshuffle"
    hierarchical: False

#Configuration for the training step
train_config:
    batch_size: 8
    epochs: 10
    optimizer: "adam"
    lr: 0.001
    betas: [0.9, 0.999]
    save_every: 5 # Once in how many epochs to checkpoint the model
    augment: True # if the training should be done with augmentation
    loss_fn: "cd"
    k_loss: 4 # only for cd_rep loss

# Configuration for loading the data
data_config:
    path: "../data/PU1K/train/pu1k_poisson_256_poisson_1024_pc_2500_patch50_addpugan.h5" # path to data directory
    num_point: 256 # number of points per sample
    skip_rate: 1
    use_randominput: True
    rng_seed: 42
